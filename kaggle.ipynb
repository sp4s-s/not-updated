{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4dcbb30b","cell_type":"code","source":"! nvcc --version\n! nvidia-smi\n! nvidia-smi topo -m","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:29:31.444519Z","iopub.execute_input":"2025-07-14T06:29:31.445723Z","iopub.status.idle":"2025-07-14T06:29:32.026716Z","shell.execute_reply.started":"2025-07-14T06:29:31.445694Z","shell.execute_reply":"2025-07-14T06:29:32.025933Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2024 NVIDIA Corporation\nBuilt on Thu_Jun__6_02:18:23_PDT_2024\nCuda compilation tools, release 12.5, V12.5.82\nBuild cuda_12.5.r12.5/compiler.34385749_0\nMon Jul 14 06:29:31 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   42C    P8             10W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   44C    P8             11W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n\t\u001b[4mGPU0\tGPU1\tCPU Affinity\tNUMA Affinity\tGPU NUMA ID\u001b[0m\nGPU0\t X \tPHB\t0-3\t0\t\tN/A\nGPU1\tPHB\t X \t0-3\t0\t\tN/A\n\nLegend:\n\n  X    = Self\n  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)\n  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)\n  PIX  = Connection traversing at most a single PCIe bridge\n  NV#  = Connection traversing a bonded set of # NVLinks\n","output_type":"stream"}],"execution_count":10},{"id":"35d7727d-ac6f-49a0-8d16-430ac22944d3","cell_type":"code","source":"!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n!bash miniconda.sh -b -p /opt/conda\n!rm miniconda.sh\n!export PATH=\"/opt/conda/bin:$PATH\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:04:02.837389Z","iopub.execute_input":"2025-07-14T06:04:02.837811Z","iopub.status.idle":"2025-07-14T06:04:18.483262Z","shell.execute_reply.started":"2025-07-14T06:04:02.837788Z","shell.execute_reply":"2025-07-14T06:04:18.482064Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"--2025-07-14 06:04:02--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nResolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:bf9e, ...\nConnecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 159476510 (152M) [application/octet-stream]\nSaving to: ‘miniconda.sh’\n\nminiconda.sh        100%[===================>] 152.09M   186MB/s    in 0.8s    \n\n2025-07-14 06:04:03 (186 MB/s) - ‘miniconda.sh’ saved [159476510/159476510]\n\nPREFIX=/opt/conda\nUnpacking payload ...\nentry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\nentry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... done\nentry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\ninstallation finished.\nWARNING:\n    You currently have a PYTHONPATH environment variable set. This may cause\n    unexpected behavior when running the Python interpreter in Miniconda3.\n    For best results, please verify that your PYTHONPATH only points to\n    directories of packages that are compatible with the Python interpreter\n    in Miniconda3: /opt/conda\n","output_type":"stream"}],"execution_count":8},{"id":"0b9df293-2f79-432b-8cba-76fcae9cfa8b","cell_type":"code","source":"!/opt/conda/bin/conda create -y -n py310 python=3.10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:04:30.427294Z","iopub.execute_input":"2025-07-14T06:04:30.427846Z","iopub.status.idle":"2025-07-14T06:04:40.045797Z","shell.execute_reply.started":"2025-07-14T06:04:30.427818Z","shell.execute_reply":"2025-07-14T06:04:40.044898Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Channels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/py310\n\n  added / updated specs:\n    - python=3.10\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    python-3.10.18             |       h1a3bd86_0        26.5 MB\n    setuptools-78.1.1          |  py310h06a4308_0         1.7 MB\n    wheel-0.45.1               |  py310h06a4308_0         115 KB\n    ------------------------------------------------------------\n                                           Total:        28.4 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.2.25-h06a4308_0 \n  expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 \n  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n  openssl            pkgs/main/linux-64::openssl-3.0.16-h5eee18b_0 \n  pip                pkgs/main/noarch::pip-25.1-pyhc872135_2 \n  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n  python             pkgs/main/linux-64::python-3.10.18-h1a3bd86_0 \n  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n  setuptools         pkgs/main/linux-64::setuptools-78.1.1-py310h06a4308_0 \n  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n  tk                 pkgs/main/linux-64::tk-8.6.14-h993c535_1 \n  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n  wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n\n\n\nDownloading and Extracting Packages:\npython-3.10.18       | 26.5 MB   |                                       |   0% \nsetuptools-78.1.1    | 1.7 MB    |                                       |   0% \u001b[A\n\nwheel-0.45.1         | 115 KB    |                                       |   0% \u001b[A\u001b[A\n\nwheel-0.45.1         | 115 KB    | ##################################### | 100% \u001b[A\u001b[A\npython-3.10.18       | 26.5 MB   | 2                                     |   1% \u001b[A\n\nwheel-0.45.1         | 115 KB    | ##################################### | 100% \u001b[A\u001b[A\n\nwheel-0.45.1         | 115 KB    | ##################################### | 100% \u001b[A\u001b[A\npython-3.10.18       | 26.5 MB   | ################5                     |  45% \u001b[A\nsetuptools-78.1.1    | 1.7 MB    | ##################################### | 100% \u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate py310\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n","output_type":"stream"}],"execution_count":9},{"id":"aa69c670-83db-4e57-bb0d-4f1e852babae","cell_type":"code","source":"!/opt/conda/envs/py310/bin/python -m pip install ipykernel\n!/opt/conda/envs/py310/bin/python -m ipykernel install --user --name py310 --display-name \"Python 3.10 (conda)\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:04:43.735206Z","iopub.execute_input":"2025-07-14T06:04:43.735967Z","iopub.status.idle":"2025-07-14T06:04:54.488464Z","shell.execute_reply.started":"2025-07-14T06:04:43.735940Z","shell.execute_reply":"2025-07-14T06:04:54.487114Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting ipykernel\n  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\nCollecting comm>=0.1.1 (from ipykernel)\n  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\nCollecting debugpy>=1.6.5 (from ipykernel)\n  Downloading debugpy-1.8.14-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting ipython>=7.23.1 (from ipykernel)\n  Downloading ipython-8.37.0-py3-none-any.whl.metadata (5.1 kB)\nCollecting jupyter-client>=6.1.12 (from ipykernel)\n  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\nCollecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n  Downloading jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting matplotlib-inline>=0.1 (from ipykernel)\n  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\nCollecting nest-asyncio (from ipykernel)\n  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting packaging (from ipykernel)\n  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting psutil (from ipykernel)\n  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nCollecting pyzmq>=24 (from ipykernel)\n  Downloading pyzmq-27.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\nCollecting tornado>=6.1 (from ipykernel)\n  Downloading tornado-6.5.1-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\nCollecting traitlets>=5.4.0 (from ipykernel)\n  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\nCollecting decorator (from ipython>=7.23.1->ipykernel)\n  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\nCollecting exceptiongroup (from ipython>=7.23.1->ipykernel)\n  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\nCollecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\nCollecting pexpect>4.3 (from ipython>=7.23.1->ipykernel)\n  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel)\n  Downloading prompt_toolkit-3.0.51-py3-none-any.whl.metadata (6.4 kB)\nCollecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel)\n  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\nCollecting stack_data (from ipython>=7.23.1->ipykernel)\n  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\nCollecting typing_extensions>=4.6 (from ipython>=7.23.1->ipykernel)\n  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel)\n  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\nCollecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel)\n  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\nCollecting python-dateutil>=2.8.2 (from jupyter-client>=6.1.12->ipykernel)\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel)\n  Downloading platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\nCollecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel)\n  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting six>=1.5 (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel)\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting executing>=1.2.0 (from stack_data->ipython>=7.23.1->ipykernel)\n  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\nCollecting asttokens>=2.1.0 (from stack_data->ipython>=7.23.1->ipykernel)\n  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\nCollecting pure-eval (from stack_data->ipython>=7.23.1->ipykernel)\n  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\nDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\nDownloading debugpy-1.8.14-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ipython-8.37.0-py3-none-any.whl (831 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.9/831.9 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading prompt_toolkit-3.0.51-py3-none-any.whl (387 kB)\nDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\nDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\nDownloading jupyter_core-5.8.1-py3-none-any.whl (28 kB)\nDownloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\nDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\nDownloading platformdirs-4.3.8-py3-none-any.whl (18 kB)\nDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\nDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\nDownloading pyzmq-27.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (853 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.8/853.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading tornado-6.5.1-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\nDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\nDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\nDownloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\nDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\nDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\nDownloading packaging-25.0-py3-none-any.whl (66 kB)\nDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\nDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\nDownloading asttokens-3.0.0-py3-none-any.whl (26 kB)\nDownloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\nDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\nDownloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\nInstalling collected packages: wcwidth, pure-eval, ptyprocess, typing_extensions, traitlets, tornado, six, pyzmq, pygments, psutil, prompt_toolkit, platformdirs, pexpect, parso, packaging, nest-asyncio, executing, decorator, debugpy, asttokens, stack_data, python-dateutil, matplotlib-inline, jupyter-core, jedi, exceptiongroup, comm, jupyter-client, ipython, ipykernel\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/30\u001b[0m [ipykernel]30\u001b[0m [ipython]ngroup]]\n\u001b[1A\u001b[2KSuccessfully installed asttokens-3.0.0 comm-0.2.2 debugpy-1.8.14 decorator-5.2.1 exceptiongroup-1.3.0 executing-2.2.0 ipykernel-6.29.5 ipython-8.37.0 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.8.1 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 packaging-25.0 parso-0.8.4 pexpect-4.9.0 platformdirs-4.3.8 prompt_toolkit-3.0.51 psutil-7.0.0 ptyprocess-0.7.0 pure-eval-0.2.3 pygments-2.19.2 python-dateutil-2.9.0.post0 pyzmq-27.0.0 six-1.17.0 stack_data-0.6.3 tornado-6.5.1 traitlets-5.14.3 typing_extensions-4.14.1 wcwidth-0.2.13\nInstalled kernelspec py310 in /root/.local/share/jupyter/kernels/py310\n","output_type":"stream"}],"execution_count":10},{"id":"1b997e84-5d22-4b54-bd1b-11e12e7077d3","cell_type":"code","source":"! python --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:10:18.999298Z","iopub.execute_input":"2025-07-14T06:10:18.999814Z","iopub.status.idle":"2025-07-14T06:10:19.125917Z","shell.execute_reply.started":"2025-07-14T06:10:18.999794Z","shell.execute_reply":"2025-07-14T06:10:19.125064Z"}},"outputs":[{"name":"stdout","text":"Python 3.11.13\n","output_type":"stream"}],"execution_count":1},{"id":"5b45ed73-9251-4d94-adff-165b90c343f3","cell_type":"code","source":"! pip show torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"cc3808cf-a670-4399-b5c8-770d45ccd1a4","cell_type":"code","source":"!pip install flash_attn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:15:07.106930Z","iopub.execute_input":"2025-07-14T06:15:07.107207Z","iopub.status.idle":"2025-07-14T06:16:27.371573Z","shell.execute_reply.started":"2025-07-14T06:15:07.107181Z","shell.execute_reply":"2025-07-14T06:16:27.370704Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting flash_attn\n  Downloading flash_attn-2.8.1.tar.gz (8.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash_attn) (2.6.0+cu124)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash_attn) (0.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->flash_attn)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->flash_attn)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->flash_attn)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->flash_attn)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->flash_attn)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->flash_attn)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->flash_attn)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->flash_attn)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->flash_attn)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->flash_attn)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash_attn) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash_attn) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: flash_attn\n  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for flash_attn: filename=flash_attn-2.8.1-cp311-cp311-linux_x86_64.whl size=126118408 sha256=5a330e5038acaa2309550110731ba580953f76d445a02d9b0d88906d97831db1\n  Stored in directory: /root/.cache/pip/wheels/fe/e8/f9/c737fa70cd4a4c0cf9f0d7e3b08b669b69893e7a1591919214\nSuccessfully built flash_attn\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, flash_attn\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed flash_attn-2.8.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":3},{"id":"b3a8d2b7","cell_type":"code","source":"! pip show torch flash-attn ","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:16:35.067944Z","iopub.execute_input":"2025-07-14T06:16:35.068562Z","iopub.status.idle":"2025-07-14T06:16:37.688497Z","shell.execute_reply.started":"2025-07-14T06:16:35.068530Z","shell.execute_reply":"2025-07-14T06:16:37.687818Z"}},"outputs":[{"name":"stdout","text":"Name: torch\nVersion: 2.6.0+cu124\nSummary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\nHome-page: https://pytorch.org/\nAuthor: PyTorch Team\nAuthor-email: packages@pytorch.org\nLicense: BSD-3-Clause\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\nRequired-by: accelerate, easyocr, fastai, flash_attn, kornia, peft, pytorch-ignite, pytorch-lightning, sentence-transformers, stable-baselines3, timm, torchaudio, torchdata, torchmetrics, torchvision\n---\nName: flash_attn\nVersion: 2.8.1\nSummary: Flash Attention: Fast and Memory-Efficient Exact Attention\nHome-page: https://github.com/Dao-AILab/flash-attention\nAuthor: Tri Dao\nAuthor-email: tri@tridao.me\nLicense: \nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: einops, torch\nRequired-by: \n","output_type":"stream"}],"execution_count":4},{"id":"a0743a34","cell_type":"code","source":"#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # or use suitable CUDA version\n!pip install \\\n    transformers \\\n    datasets \\\n    peft \\\n    trl \\\n    bitsandbytes \\\n    packaging \\\n    ninja \\\n    wandb \\\n    # flash-attn \\\n    accelerate \\\n    huggingface_hub \\\n    sentencepiece \\\n    git+https://github.com/huggingface/peft.git \\\n    git+https://github.com/huggingface/transformers.git \\\n    git+https://github.com/huggingface/trl.git\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:30:05.967205Z","iopub.execute_input":"2025-07-14T06:30:05.968002Z","iopub.status.idle":"2025-07-14T06:30:09.456427Z","shell.execute_reply.started":"2025-07-14T06:30:05.967968Z","shell.execute_reply":"2025-07-14T06:30:09.455694Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0.dev0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.1.dev0)\nRequirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.20.0.dev0)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (25.0)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.20.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.8.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.31.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\nRequirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":12},{"id":"5c5541f7-c1b7-4570-b223-88ae50b5ee72","cell_type":"code","source":"!git clone https://github.com/Dao-AILab/flash-attention.git\n%cd flash-attention\n!git checkout v1.0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:20:24.430599Z","iopub.execute_input":"2025-07-14T06:20:24.431368Z","iopub.status.idle":"2025-07-14T06:20:25.709328Z","shell.execute_reply.started":"2025-07-14T06:20:24.431335Z","shell.execute_reply":"2025-07-14T06:20:25.708681Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Cloning into 'flash-attention'...\nremote: Enumerating objects: 10203, done.\u001b[K\nremote: Counting objects: 100% (2882/2882), done.\u001b[K\nremote: Compressing objects: 100% (273/273), done.\u001b[K\nremote: Total 10203 (delta 2719), reused 2622 (delta 2606), pack-reused 7321 (from 2)\u001b[K\nReceiving objects: 100% (10203/10203), 9.79 MiB | 31.94 MiB/s, done.\nResolving deltas: 100% (7880/7880), done.\n/kaggle/working/flash-attention\nNote: switching to 'v1.0.5'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at eff9fe6 Add ninja to pyproject.toml build-system, bump to v1.0.5\n","output_type":"stream"}],"execution_count":6},{"id":"ec233009-db41-4965-9b64-f9cf8971a269","cell_type":"code","source":"!pip install packaging ninja  # prerequisites\n!pip install flash-attn --no-build-isolation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:28:04.015562Z","iopub.execute_input":"2025-07-14T06:28:04.015824Z","iopub.status.idle":"2025-07-14T06:28:10.053984Z","shell.execute_reply.started":"2025-07-14T06:28:04.015800Z","shell.execute_reply":"2025-07-14T06:28:10.053080Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (25.0)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\nRequirement already satisfied: flash-attn in /usr/local/lib/python3.11/dist-packages (2.8.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.6.0+cu124)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n","output_type":"stream"}],"execution_count":8},{"id":"29322141-7875-45e3-bb12-79871043c23b","cell_type":"code","source":"! pip install packaging ninja\n! pip install .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:20:41.671615Z","iopub.execute_input":"2025-07-14T06:20:41.672036Z","iopub.status.idle":"2025-07-14T06:27:22.543630Z","shell.execute_reply.started":"2025-07-14T06:20:41.672005Z","shell.execute_reply":"2025-07-14T06:27:22.542909Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (25.0)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\nProcessing /kaggle/working/flash-attention\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash_attn==1.0.5) (2.6.0+cu124)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash_attn==1.0.5) (0.8.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from flash_attn==1.0.5) (25.0)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from flash_attn==1.0.5) (1.11.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn==1.0.5) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash_attn==1.0.5) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash_attn==1.0.5) (3.0.2)\nBuilding wheels for collected packages: flash_attn\n^C\n  Building wheel for flash_attn (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":7},{"id":"6c0f32d4-86bb-4693-af6b-0993aac51632","cell_type":"code","source":"# ! pip uninstall -y flash-attn\n# ! pip install flash-attn --no-cache-dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:01:47.944579Z","iopub.execute_input":"2025-07-14T06:01:47.944939Z","iopub.status.idle":"2025-07-14T06:02:34.438924Z","shell.execute_reply.started":"2025-07-14T06:01:47.944912Z","shell.execute_reply":"2025-07-14T06:02:34.437881Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Found existing installation: flash_attn 2.8.1\nUninstalling flash_attn-2.8.1:\n  Successfully uninstalled flash_attn-2.8.1\nCollecting flash-attn\n  Downloading flash_attn-2.8.1.tar.gz (8.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.6.0+cu124)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\nBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for flash-attn: filename=flash_attn-2.8.1-cp311-cp311-linux_x86_64.whl size=126118408 sha256=5a330e5038acaa2309550110731ba580953f76d445a02d9b0d88906d97831db1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-fewswdlj/wheels/fe/e8/f9/c737fa70cd4a4c0cf9f0d7e3b08b669b69893e7a1591919214\nSuccessfully built flash-attn\nInstalling collected packages: flash-attn\nSuccessfully installed flash-attn-2.8.1\n","output_type":"stream"}],"execution_count":6},{"id":"d600380b-bd81-494e-9380-c0beff3705cb","cell_type":"code","source":"# import os\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nos.environ[\"WANDB_API_KEY\"] = user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"HF_TOKEN\"] = user_secrets.get_secret(\"HF_TOKEN\")\n!wandb login $WANDB_API_KEY\n!huggingface-cli login --token $HF_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:36:11.504982Z","iopub.execute_input":"2025-07-14T06:36:11.505750Z","iopub.status.idle":"2025-07-14T06:36:13.911510Z","shell.execute_reply.started":"2025-07-14T06:36:11.505717Z","shell.execute_reply":"2025-07-14T06:36:13.910531Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\nThe token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nThe token `tpudfsa` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nNote: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n","output_type":"stream"}],"execution_count":21},{"id":"03224dad","cell_type":"code","source":"import os\nimport subprocess\nimport gc\nimport logging\nfrom pathlib import Path\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n)\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\nfrom trl import setup_chat_format\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:30:25.155998Z","iopub.execute_input":"2025-07-14T06:30:25.156548Z","iopub.status.idle":"2025-07-14T06:30:25.160680Z","shell.execute_reply.started":"2025-07-14T06:30:25.156521Z","shell.execute_reply":"2025-07-14T06:30:25.159823Z"}},"outputs":[],"execution_count":14},{"id":"a3937be8-da75-4fc1-bac8-560869eea3a5","cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:00:36.255833Z","iopub.execute_input":"2025-07-14T06:00:36.256648Z","iopub.status.idle":"2025-07-14T06:00:36.405068Z","shell.execute_reply.started":"2025-07-14T06:00:36.256617Z","shell.execute_reply":"2025-07-14T06:00:36.404121Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: conda: command not found\n","output_type":"stream"}],"execution_count":5},{"id":"a772d396","cell_type":"code","source":"def run(cmd, cwd=None):\n    result = subprocess.run(cmd, shell=True, cwd=cwd, capture_output=True, text=True)\n    print(result.stdout)\n    if result.returncode != 0:\n        print(result.stderr)\n        raise RuntimeError(f\"Command failed: {cmd}\")\n    return result\n\ndef setup_flash_attention():\n    if torch.cuda.get_device_capability()[0] >= 8:\n        try:\n            subprocess.run([\"pip\", \"uninstall\", \"-y\", \"flash-attn\"], check=False)\n\n            repo_url = \"https://github.com/Dao-AILab/flash-attention.git\"\n            clone_dir = Path(\"flash-attention\")\n            if not clone_dir.exists():\n                run(f\"git clone {repo_url}\")\n\n            run(\"pip install packaging ninja\", cwd=clone_dir)\n            run(\"pip install .\", cwd=clone_dir)\n\n            attn_implementation = \"flash_attention_2\"\n            torch_dtype = torch.bfloat16\n\n        except Exception as e:\n            print(f\"⚠️ Failed to install flash-attn from source: {e}\")\n            attn_implementation = \"eager\"\n            torch_dtype = torch.float16\n    else:\n        print(\"⚠️ GPU compute capability < 8.0 — falling back to eager attention.\")\n        attn_implementation = \"eager\"\n        torch_dtype = torch.float16\n\n    return attn_implementation, torch_dtype\n\nattn_implementation, torch_dtype = setup_flash_attention()\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:37:10.615940Z","iopub.execute_input":"2025-07-14T06:37:10.616541Z","iopub.status.idle":"2025-07-14T06:37:10.623070Z","shell.execute_reply.started":"2025-07-14T06:37:10.616515Z","shell.execute_reply":"2025-07-14T06:37:10.622404Z"}},"outputs":[{"name":"stdout","text":"⚠️ GPU compute capability < 8.0 — falling back to eager attention.\n","output_type":"stream"}],"execution_count":24},{"id":"4f0dc291","cell_type":"code","source":"logging.basicConfig(\n    filename=\"main_output.log\",\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n)\n\nlogging.info(f\"Attention backend: {attn_implementation}\")\nlogging.info(f\"Using dtype: {torch_dtype}\")\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:37:22.079271Z","iopub.execute_input":"2025-07-14T06:37:22.079559Z","iopub.status.idle":"2025-07-14T06:37:22.083744Z","shell.execute_reply.started":"2025-07-14T06:37:22.079538Z","shell.execute_reply":"2025-07-14T06:37:22.082943Z"}},"outputs":[],"execution_count":26},{"id":"4c2aa7fa-900c-42f0-a676-c72181359021","cell_type":"code","source":"%env HF_ENABLE_HF_TRANSFER","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e5963338","cell_type":"code","source":"base_model = \"meta-llama/Meta-Llama-3-8B\"\nnew_model = \"OrpoLlama-3-8B\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\n\ntokenizer = AutoTokenizer.from_pretrained(base_model)\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=attn_implementation\n)\n\ntokenizer.chat_template = None\nmodel, tokenizer = setup_chat_format(model, tokenizer)\nmodel = prepare_model_for_kbit_training(model)\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:37:29.916516Z","iopub.execute_input":"2025-07-14T06:37:29.917245Z","iopub.status.idle":"2025-07-14T06:40:30.894512Z","shell.execute_reply.started":"2025-07-14T06:37:29.917210Z","shell.execute_reply":"2025-07-14T06:40:30.893702Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed48af2a01b24198a7b5438dc66d852d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"637aafff6755490687d6b385fa36400f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2a29e202b9244aabb7b21cc2fac2388"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d5c5840a33e494cba5e4dd5a6ed7aab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93afba361ab48968ae443ccb569d79e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94434b2cf8124300b1b08a201d319518"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dfc8c2b8cd9400f86304e6c107ca651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"178116d3cdf0468982d1d78e1e3f060f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec8481cb50747529ff74385b0d5f524"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb29e5965089418b946c7e503f7ea7c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d7a372c81ef4632bff823ca0f30359d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25c2c5334c6742aab99669b44c8ac495"}},"metadata":{}},{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\nThe new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"}],"execution_count":27},{"id":"90787e45-93dd-4226-ba40-8c953cf40bf7","cell_type":"code","source":"! pip install -qU hf_transfer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:40:30.895719Z","iopub.execute_input":"2025-07-14T06:40:30.895983Z","iopub.status.idle":"2025-07-14T06:40:35.379797Z","shell.execute_reply.started":"2025-07-14T06:40:30.895956Z","shell.execute_reply":"2025-07-14T06:40:35.378947Z"}},"outputs":[],"execution_count":28},{"id":"7f12e426-2663-4d17-8e14-d16b96453118","cell_type":"code","source":"%env HF_ENABLE_HF_TRANSFER=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:40:35.387910Z","iopub.execute_input":"2025-07-14T06:40:35.388091Z","iopub.status.idle":"2025-07-14T06:40:35.398735Z","shell.execute_reply.started":"2025-07-14T06:40:35.388078Z","shell.execute_reply":"2025-07-14T06:40:35.398065Z"}},"outputs":[{"name":"stdout","text":"env: HF_ENABLE_HF_TRANSFER=1\n","output_type":"stream"}],"execution_count":30},{"id":"cc0a8242","cell_type":"code","source":"dataset_name = \"mlabonne/orpo-dpo-mix-40k\"\ndataset = load_dataset(dataset_name, split=\"all\")\ndataset = dataset.shuffle(seed=42).select(range(100))\n\ndef format_chat_template(row):\n    row[\"chosen\"] = tokenizer.apply_chat_template(row[\"chosen\"], tokenize=False)\n    row[\"rejected\"] = tokenizer.apply_chat_template(row[\"rejected\"], tokenize=False)\n    return row\n\ndataset = dataset.map(format_chat_template, num_proc=os.cpu_count())\ndataset = dataset.train_test_split(test_size=0.01)\n","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:40:43.589698Z","iopub.execute_input":"2025-07-14T06:40:43.589980Z","iopub.status.idle":"2025-07-14T06:40:48.115185Z","shell.execute_reply.started":"2025-07-14T06:40:43.589961Z","shell.execute_reply":"2025-07-14T06:40:48.114278Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf7abab93a647a993882afa20df4e16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/127M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eebda6505cb42709670d628bff34d93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/44245 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b7c4eeecbfe436ca741faba1dda7ba7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c7ef5dfbc44c698c7c6dcc802752ad"}},"metadata":{}}],"execution_count":31},{"id":"e561d15c","cell_type":"code","source":"from trl import ORPOConfig, ORPOTrainer\n\ndef get_orpo_args():\n    return ORPOConfig(\n        output_dir=\"./results/\",\n        overwrite_output_dir=True,\n        learning_rate=8e-6,\n        beta=0.1,\n        lr_scheduler_type=\"linear\",\n        per_device_train_batch_size=2,\n        per_device_eval_batch_size=2,\n        gradient_accumulation_steps=4,\n        optim=\"paged_adamw_8bit\",\n        num_train_epochs=1,\n        eval_strategy=\"steps\",\n        eval_accumulation_steps=2,\n        logging_steps=1,\n        report_to=\"wandb\",\n        max_length=1024,\n        max_prompt_length=512,\n        bf16=True,\n        fp16=False,\n        save_strategy=\"epoch\",\n    )\n\ndef orpo_trainer(model, dataset, tokenizer, peft_config):\n    orpo_args = get_orpo_args()\n    trainer = ORPOTrainer(\n        model=model,\n        args=orpo_args,\n        train_dataset=dataset[\"train\"],\n        eval_dataset=dataset[\"test\"],\n        processing_class=tokenizer,\n        peft_config=peft_config,\n    )\n    return trainer","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:41:21.569234Z","iopub.execute_input":"2025-07-14T06:41:21.569519Z","iopub.status.idle":"2025-07-14T06:41:21.574994Z","shell.execute_reply.started":"2025-07-14T06:41:21.569497Z","shell.execute_reply":"2025-07-14T06:41:21.574240Z"}},"outputs":[],"execution_count":34},{"id":"11caad24","cell_type":"code","source":"trainer = orpo_trainer(model=model, dataset=dataset, tokenizer=tokenizer, peft_config=peft_config)\ntrainer.train()\ntrainer.save_model(new_model)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:41:28.238694Z","iopub.execute_input":"2025-07-14T06:41:28.238971Z","iopub.status.idle":"2025-07-14T07:40:58.372803Z","shell.execute_reply.started":"2025-07-14T06:41:28.238950Z","shell.execute_reply":"2025-07-14T07:40:58.371620Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/trl/trainer/orpo_trainer.py:271: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/99 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4adde5edc3ff452087ad16345b7d60f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/99 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e62edb80d0e84730a74fbd9ed01e53e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/99 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"518315e37ea74c2c9f2458bdb5bac413"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5454ac2f21b04365a3d530109756ce79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b1b7919e0d481fa1a98a380bf6a880"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eb2797ea82d4679966aa7e6989834fa"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpigsty\u001b[0m (\u001b[33mpigsty-na\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/flash-attention/wandb/run-20250714_064136-fxidn011</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pigsty-na/huggingface/runs/fxidn011' target=\"_blank\">./results/</a></strong> to <a href='https://wandb.ai/pigsty-na/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pigsty-na/huggingface' target=\"_blank\">https://wandb.ai/pigsty-na/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pigsty-na/huggingface/runs/fxidn011' target=\"_blank\">https://wandb.ai/pigsty-na/huggingface/runs/fxidn011</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [13/13 54:15, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/rejected</th>\n      <th>Logps/chosen</th>\n      <th>Logits/rejected</th>\n      <th>Logits/chosen</th>\n      <th>Nll Loss</th>\n      <th>Log Odds Ratio</th>\n      <th>Log Odds Chosen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.483300</td>\n      <td>2.494976</td>\n      <td>7.479300</td>\n      <td>0.134000</td>\n      <td>0.134000</td>\n      <td>-0.149294</td>\n      <td>-0.108048</td>\n      <td>0.000000</td>\n      <td>-0.041246</td>\n      <td>-1.080480</td>\n      <td>-1.492940</td>\n      <td>-1.334322</td>\n      <td>-0.252808</td>\n      <td>2.392988</td>\n      <td>-1.019881</td>\n      <td>-0.572596</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.636000</td>\n      <td>2.489326</td>\n      <td>7.645500</td>\n      <td>0.131000</td>\n      <td>0.131000</td>\n      <td>-0.149089</td>\n      <td>-0.108028</td>\n      <td>0.000000</td>\n      <td>-0.041062</td>\n      <td>-1.080275</td>\n      <td>-1.490894</td>\n      <td>-1.333377</td>\n      <td>-0.242135</td>\n      <td>2.387486</td>\n      <td>-1.018392</td>\n      <td>-0.570267</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.281600</td>\n      <td>2.487611</td>\n      <td>7.481000</td>\n      <td>0.134000</td>\n      <td>0.134000</td>\n      <td>-0.148959</td>\n      <td>-0.107578</td>\n      <td>0.000000</td>\n      <td>-0.041381</td>\n      <td>-1.075779</td>\n      <td>-1.489588</td>\n      <td>-1.331713</td>\n      <td>-0.244367</td>\n      <td>2.385444</td>\n      <td>-1.021672</td>\n      <td>-0.575397</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.807000</td>\n      <td>2.483903</td>\n      <td>7.597100</td>\n      <td>0.132000</td>\n      <td>0.132000</td>\n      <td>-0.148553</td>\n      <td>-0.107492</td>\n      <td>0.000000</td>\n      <td>-0.041062</td>\n      <td>-1.074916</td>\n      <td>-1.485532</td>\n      <td>-1.329563</td>\n      <td>-0.230183</td>\n      <td>2.381987</td>\n      <td>-1.019159</td>\n      <td>-0.571467</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.345200</td>\n      <td>2.482682</td>\n      <td>7.678500</td>\n      <td>0.130000</td>\n      <td>0.130000</td>\n      <td>-0.148490</td>\n      <td>-0.107545</td>\n      <td>0.000000</td>\n      <td>-0.040944</td>\n      <td>-1.075454</td>\n      <td>-1.484896</td>\n      <td>-1.330320</td>\n      <td>-0.240068</td>\n      <td>2.380870</td>\n      <td>-1.018111</td>\n      <td>-0.569827</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.258800</td>\n      <td>2.472868</td>\n      <td>7.609100</td>\n      <td>0.131000</td>\n      <td>0.131000</td>\n      <td>-0.147594</td>\n      <td>-0.106886</td>\n      <td>0.000000</td>\n      <td>-0.040707</td>\n      <td>-1.068864</td>\n      <td>-1.475939</td>\n      <td>-1.328542</td>\n      <td>-0.220022</td>\n      <td>2.371158</td>\n      <td>-1.017104</td>\n      <td>-0.568251</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.696800</td>\n      <td>2.472044</td>\n      <td>7.993600</td>\n      <td>0.125000</td>\n      <td>0.125000</td>\n      <td>-0.147614</td>\n      <td>-0.107012</td>\n      <td>0.000000</td>\n      <td>-0.040602</td>\n      <td>-1.070122</td>\n      <td>-1.476138</td>\n      <td>-1.329863</td>\n      <td>-0.224258</td>\n      <td>2.370440</td>\n      <td>-1.016047</td>\n      <td>-0.566594</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.442600</td>\n      <td>2.473230</td>\n      <td>7.524500</td>\n      <td>0.133000</td>\n      <td>0.133000</td>\n      <td>-0.147436</td>\n      <td>-0.106678</td>\n      <td>0.000000</td>\n      <td>-0.040758</td>\n      <td>-1.066776</td>\n      <td>-1.474356</td>\n      <td>-1.327841</td>\n      <td>-0.214301</td>\n      <td>2.371448</td>\n      <td>-1.017826</td>\n      <td>-0.569380</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.586000</td>\n      <td>2.459084</td>\n      <td>7.633900</td>\n      <td>0.131000</td>\n      <td>0.131000</td>\n      <td>-0.146147</td>\n      <td>-0.106224</td>\n      <td>0.000000</td>\n      <td>-0.039923</td>\n      <td>-1.062240</td>\n      <td>-1.461472</td>\n      <td>-1.324242</td>\n      <td>-0.196936</td>\n      <td>2.357928</td>\n      <td>-1.011568</td>\n      <td>-0.559564</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.630100</td>\n      <td>2.477849</td>\n      <td>7.464500</td>\n      <td>0.134000</td>\n      <td>0.134000</td>\n      <td>-0.147908</td>\n      <td>-0.106803</td>\n      <td>0.000000</td>\n      <td>-0.041104</td>\n      <td>-1.068033</td>\n      <td>-1.479077</td>\n      <td>-1.331434</td>\n      <td>-0.217733</td>\n      <td>2.375797</td>\n      <td>-1.020512</td>\n      <td>-0.573584</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.693300</td>\n      <td>2.478813</td>\n      <td>7.621500</td>\n      <td>0.131000</td>\n      <td>0.131000</td>\n      <td>-0.148128</td>\n      <td>-0.106955</td>\n      <td>0.000000</td>\n      <td>-0.041173</td>\n      <td>-1.069550</td>\n      <td>-1.481275</td>\n      <td>-1.331882</td>\n      <td>-0.225701</td>\n      <td>2.376728</td>\n      <td>-1.020854</td>\n      <td>-0.574119</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.529200</td>\n      <td>2.473969</td>\n      <td>7.508500</td>\n      <td>0.133000</td>\n      <td>0.133000</td>\n      <td>-0.147741</td>\n      <td>-0.106676</td>\n      <td>0.000000</td>\n      <td>-0.041066</td>\n      <td>-1.066758</td>\n      <td>-1.477414</td>\n      <td>-1.328499</td>\n      <td>-0.217169</td>\n      <td>2.371931</td>\n      <td>-1.020377</td>\n      <td>-0.573372</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.638600</td>\n      <td>2.465760</td>\n      <td>7.967000</td>\n      <td>0.126000</td>\n      <td>0.126000</td>\n      <td>-0.146844</td>\n      <td>-0.106564</td>\n      <td>0.000000</td>\n      <td>-0.040280</td>\n      <td>-1.065639</td>\n      <td>-1.468436</td>\n      <td>-1.330257</td>\n      <td>-0.206310</td>\n      <td>2.364357</td>\n      <td>-1.014030</td>\n      <td>-0.563430</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":35},{"id":"ae889f66","cell_type":"code","source":"# del trainer, model\n# gc.collect()\ntorch.cuda.empty_cache()","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:47:28.913339Z","iopub.execute_input":"2025-07-14T07:47:28.913632Z","iopub.status.idle":"2025-07-14T07:47:29.359738Z","shell.execute_reply.started":"2025-07-14T07:47:28.913609Z","shell.execute_reply":"2025-07-14T07:47:29.359104Z"}},"outputs":[],"execution_count":47},{"id":"391be6d2-b35d-43e7-ae8e-1f0084741a31","cell_type":"code","source":"del model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:46:43.682335Z","iopub.execute_input":"2025-07-14T07:46:43.683211Z","iopub.status.idle":"2025-07-14T07:46:43.687687Z","shell.execute_reply.started":"2025-07-14T07:46:43.683167Z","shell.execute_reply":"2025-07-14T07:46:43.687103Z"}},"outputs":[],"execution_count":45},{"id":"665fb09d","cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model)\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\n\nmodel = PeftModel.from_pretrained(model, new_model)\nmodel = model.merge_and_unload()\n\nmodel.push_to_hub(new_model)\ntokenizer.push_to_hub(new_model)\n\nprint(\"✅ Finished everything successfully!\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:45:25.303631Z","iopub.execute_input":"2025-07-14T07:45:25.304376Z","iopub.status.idle":"2025-07-14T07:46:31.468286Z","shell.execute_reply.started":"2025-07-14T07:45:25.304352Z","shell.execute_reply":"2025-07-14T07:46:31.467143Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954959d9f8df4b2aa579f1ed769a5ac8"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1441295978.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_chat_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/models/utils.py\u001b[0m in \u001b[0;36msetup_chat_format\u001b[0;34m(model, tokenizer, format, resize_to_multiple_of)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# resize embedding layer to a multiple of 64, https://x.com/karpathy/status/1621578354024677377\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     model.resize_token_embeddings(\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;31m# After studying many tokenizers, we found that len(tokenizer.vocab) is the most reliable way to get the vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# size. Avoid using tokenizer.vocab_size or tokenizer.vocab_size + len(tokenizer.added_tokens_encoder),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mresize_token_embeddings\u001b[0;34m(self, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   3023\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPointer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0mEmbeddings\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \"\"\"\n\u001b[0;32m-> 3025\u001b[0;31m         \u001b[0mmodel_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_resizing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_num_tokens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3027\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_resize_token_embeddings\u001b[0;34m(self, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   3048\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_resizing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m         \u001b[0mold_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m         new_embeddings = self._get_resized_embeddings(\n\u001b[0m\u001b[1;32m   3051\u001b[0m             \u001b[0mold_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_resizing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_resized_embeddings\u001b[0;34m(self, old_embeddings, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   3205\u001b[0m                     )\n\u001b[1;32m   3206\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3207\u001b[0;31m                 self._init_added_embeddings_weights_with_mean(\n\u001b[0m\u001b[1;32m   3208\u001b[0m                     \u001b[0mold_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_embedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madded_num_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_init_added_embeddings_weights_with_mean\u001b[0;34m(self, old_embeddings, new_embeddings, old_embedding_dim, old_num_tokens, added_num_tokens)\u001b[0m\n\u001b[1;32m   3378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_embedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_num_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madded_num_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3379\u001b[0m     ):\n\u001b[0;32m-> 3380\u001b[0;31m         \u001b[0mold_embeddings_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3381\u001b[0m         \u001b[0mmean_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_embeddings_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m         \u001b[0mold_centered_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_embeddings_weight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 14.74 GiB of which 314.12 MiB is free. Process 2560 has 14.31 GiB memory in use. Of the allocated memory 14.09 GiB is allocated by PyTorch, and 52.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 14.74 GiB of which 314.12 MiB is free. Process 2560 has 14.31 GiB memory in use. Of the allocated memory 14.09 GiB is allocated by PyTorch, and 52.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":44},{"id":"d8bea124","cell_type":"code","source":"print(tokenizer.chat_template)","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:42:26.658160Z","iopub.status.idle":"2025-07-14T07:42:26.658504Z","shell.execute_reply.started":"2025-07-14T07:42:26.658329Z","shell.execute_reply":"2025-07-14T07:42:26.658344Z"}},"outputs":[],"execution_count":null},{"id":"ddfa0dce","cell_type":"code","source":"%cd ..","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:49:50.033133Z","iopub.execute_input":"2025-07-14T07:49:50.033452Z","iopub.status.idle":"2025-07-14T07:49:50.041476Z","shell.execute_reply.started":"2025-07-14T07:49:50.033428Z","shell.execute_reply":"2025-07-14T07:49:50.040834Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":50},{"id":"db38a5a0","cell_type":"code","source":"! mkdir -p ds","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:50:07.223534Z","iopub.execute_input":"2025-07-14T07:50:07.223871Z","iopub.status.idle":"2025-07-14T07:50:07.620715Z","shell.execute_reply.started":"2025-07-14T07:50:07.223845Z","shell.execute_reply":"2025-07-14T07:50:07.619725Z"}},"outputs":[],"execution_count":52},{"id":"025f6ed8","cell_type":"code","source":"!ls","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:50:11.013618Z","iopub.execute_input":"2025-07-14T07:50:11.014053Z","iopub.status.idle":"2025-07-14T07:50:11.425159Z","shell.execute_reply.started":"2025-07-14T07:50:11.014027Z","shell.execute_reply":"2025-07-14T07:50:11.424282Z"}},"outputs":[{"name":"stdout","text":"ds  flash-attention\n","output_type":"stream"}],"execution_count":53},{"id":"4ee2cec0","cell_type":"code","source":"base_model.save_to_disk(\"/kaggle/working/ds\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:51:17.232902Z","iopub.execute_input":"2025-07-14T07:51:17.233171Z","iopub.status.idle":"2025-07-14T07:51:17.256893Z","shell.execute_reply.started":"2025-07-14T07:51:17.233154Z","shell.execute_reply":"2025-07-14T07:51:17.255870Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3592553477.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/ds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'save_to_disk'"],"ename":"AttributeError","evalue":"'str' object has no attribute 'save_to_disk'","output_type":"error"}],"execution_count":55},{"id":"b6a61a3c-40f3-4848-b02b-5c05de43225f","cell_type":"code","source":"new_model.save_to_disk(\"/kaggle/working/ds\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-14T08:08:33.504Z"}},"outputs":[],"execution_count":null},{"id":"6a5f53cc","cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"cpu\")","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:52:39.166453Z","iopub.execute_input":"2025-07-14T07:52:39.167176Z","execution_failed":"2025-07-14T08:08:33.504Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ea6140ce0224c6bba53c86578e132f4"}},"metadata":{}}],"execution_count":null},{"id":"2f1e527e","cell_type":"code","source":"model, tokenizer = setup_chat_format(model, tokenizer)\n\nmodel = PeftModel.from_pretrained(model, new_model)\nmodel = model.merge_and_unload()\n\nmodel.push_to_hub(new_model)\ntokenizer.push_to_hub(new_model)\n\nprint(\"✅ Finished everything successfully!\")","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"execution_count":null},{"id":"0148c9e3","cell_type":"code","source":"","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"execution_count":null},{"id":"f62ce69b","cell_type":"code","source":"","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"execution_count":null},{"id":"7932bc0f","cell_type":"code","source":"","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"execution_count":null},{"id":"612f72ae","cell_type":"code","source":"","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"execution_count":null},{"id":"27b4d50f","cell_type":"code","source":"","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"execution_count":null},{"id":"4dc3d33f","cell_type":"code","source":"","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"execution_count":null},{"id":"9108d441","cell_type":"code","source":"","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"execution_count":null}]}